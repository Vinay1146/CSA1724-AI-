import numpy as np

# Activation function
def sigmoid(x): return 1 / (1 + np.exp(-x))
def d_sigmoid(x): return x * (1 - x)

# Dataset (XOR problem)
X = np.array([[0,0],[0,1],[1,0],[1,1]])
y = np.array([[0],[1],[1],[0]])

# Weights and biases
np.random.seed(0)
w1 = np.random.rand(2, 2)
b1 = np.zeros((1, 2))
w2 = np.random.rand(2, 1)
b2 = np.zeros((1, 1))

# Training
for _ in range(10000):
    h = sigmoid(np.dot(X, w1) + b1)
    o = sigmoid(np.dot(h, w2) + b2)

    # Backpropagation
    error = y - o
    d_o = error * d_sigmoid(o)
    d_h = d_o.dot(w2.T) * d_sigmoid(h)

    w2 += h.T.dot(d_o) * 0.1
    b2 += np.sum(d_o, axis=0, keepdims=True) * 0.1
    w1 += X.T.dot(d_h) * 0.1
    b1 += np.sum(d_h, axis=0, keepdims=True) * 0.1

# Output
print("Predicted:\n", o.round(3))
